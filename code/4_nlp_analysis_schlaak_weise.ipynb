{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation der Daten\n",
    "\n",
    "In diesem Notebook möchten wir eine Cluster Analyse unserer zuvor vor verarbeiteten Daten durchführen, um inhaltlich ähnliche Filme zu einem Genre zu ordnen zu können. basierend darauf soll eine Ähnlichkeitsanalyse innerhalb jedes Clusters durchgeführt werden, um Vorschläge für ähnliche Titel aussprechen zu können.\n",
    "\n",
    "## Module importieren\n",
    "\n",
    "Zur Verarbeitung der Datenbasis werden folgende Module benötigt und müssen zuerst importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../data/movies.json'\n",
    "# JSON Daten in Dataframe lesen\n",
    "data = pd.read_json(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenbereinigung\n",
    "\n",
    "Entfernen der Dateneinträge ohne Zusammenfassung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    }
   ],
   "source": [
    "disclaimer = 'It looks like we don\\'t have a Synopsis for this title yet.'\n",
    "for index, movie in data.iterrows():\n",
    "    if disclaimer in movie['synopsis']:\n",
    "        data = data.drop(index)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorverarbeitung der Daten\n",
    "\n",
    "Lemmatisierung der Token, sowie entfernen von Stoppwörtern, Eigennamen und Verben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for index, movie in data.iterrows():\n",
    "    # Vorverarbeiten der Zusammenfassungen\n",
    "    processed_data.append({'title': movie['title'], 'bow': ' '.join([str(token.lemma_).lower() for token in nlp(movie['synopsis']) if not token.ent_type_ and not token.is_stop and not token.is_punct and token.pos_ != 'VERB'])})\n",
    "data = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das DataFrame sieht nun folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>banker wife lover golf pro state death penalty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>movie gang man clown mask bank mob large porti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>guest wedding reception daughter connie head f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>godfather ii parallel storyline chief event mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>restaurant young couple pro con bank versus li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title                                                bow\n",
       "0  The Shawshank Redemption  banker wife lover golf pro state death penalty...\n",
       "1           The Dark Knight  movie gang man clown mask bank mob large porti...\n",
       "2             The Godfather  guest wedding reception daughter connie head f...\n",
       "3    The Godfather: Part II  godfather ii parallel storyline chief event mo...\n",
       "4              Pulp Fiction  restaurant young couple pro con bank versus li..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nur erste fünf Einträge anzeigen\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-Matrix erstellen\n",
    "\n",
    "\n",
    "Damit wir unsere vorverarbeitenden Bag of Words als Eingabe für unsere Cluster Algorithmus verwenden können erstellen wir eine so genannte Feature Matrix. Dabei generieren wir eine Matrix der Häufigkeit aller Token unsere Dateneinträge mithilfe des von `sklearn`s `CountVectorizer` gefolgt von einer Normalisierung mittels `TfidfTransformer` der Daten. Wir nutzen hierbei die Inverse Dokument Frequency (inverse Dokumentenhäufigkeit). Die inverse Dokumenthäufigkeit misst die Spezifität eines Terms für die Gesamtmenge der betrachteten Dokumente. Ein übereinstimmendes Vorkommen von seltenen Begriffen ist für die Relevanz aussagekräftiger als eine Übereinstimmung bei sehr häufigen Wörtern [[Quelle]](https://de.wikipedia.org/wiki/Tf-idf-Ma%C3%9F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix von Token mit Frequenz plus Normalisieren mittels \"Inverse-document-frequency\" (IDF)\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.2, ngram_range=(1,3))\n",
    "# Lernen des Vokabulars und IDF\n",
    "X = vectorizer.fit_transform(data['bow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere Feature Matrix besteht somit aus 237 Einträgen, die jeweils über 196 Wörter/Token verfügen. Jeder Dateneintrag besitzt selbstverständlich nicht jedes Wort und hat deshalb bei mehreren Token eine Frequenz von 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 196)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten folgende Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0353196 , 0.02406543, 0.        , ..., 0.02499595, 0.07219628,\n",
       "        0.01581857],\n",
       "       [0.04885937, 0.02219394, 0.04252334, ..., 0.        , 0.02219394,\n",
       "        0.02917682],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.12084285],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.04800141, ..., 0.        , 0.        ,\n",
       "        0.06587104],\n",
       "       [0.        , 0.        , 0.        , ..., 0.07059206, 0.        ,\n",
       "        0.13402154],\n",
       "       [0.0483163 , 0.06584177, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten somit 196 Wörter, welche das für dieses Projekt benötigte Vokabular darstellen. Bei einer Optimierung dieses Projekts könnte man beispielsweise dieses Vokabular  (erweitert mit Stoppwörtern, Satzzeichen) anstatt eines der von spaCy zur Verügung gestellten Sprachmodelle nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'action',\n",
       " 'actually',\n",
       " 'alive',\n",
       " 'angry',\n",
       " 'apartment',\n",
       " 'apparently',\n",
       " 'area',\n",
       " 'arm',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'away',\n",
       " 'bad',\n",
       " 'bar',\n",
       " 'battle',\n",
       " 'bed',\n",
       " 'big',\n",
       " 'black',\n",
       " 'blood',\n",
       " 'body',\n",
       " 'book',\n",
       " 'boy',\n",
       " 'brother',\n",
       " 'building',\n",
       " 'business',\n",
       " 'car',\n",
       " 'case',\n",
       " 'chance',\n",
       " 'charge',\n",
       " 'child',\n",
       " 'city',\n",
       " 'close',\n",
       " 'company',\n",
       " 'completely',\n",
       " 'control',\n",
       " 'conversation',\n",
       " 'couple',\n",
       " 'crime',\n",
       " 'dark',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'despite',\n",
       " 'different',\n",
       " 'doctor',\n",
       " 'door',\n",
       " 'earlier',\n",
       " 'end',\n",
       " 'entire',\n",
       " 'escape',\n",
       " 'event',\n",
       " 'eventually',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'family',\n",
       " 'far',\n",
       " 'father',\n",
       " 'fight',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'fire',\n",
       " 'floor',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'force',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'game',\n",
       " 'girl',\n",
       " 'good',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'guard',\n",
       " 'gun',\n",
       " 'hand',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'head',\n",
       " 'help',\n",
       " 'high',\n",
       " 'home',\n",
       " 'hospital',\n",
       " 'house',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'immediately',\n",
       " 'information',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'job',\n",
       " 'large',\n",
       " 'late',\n",
       " 'later',\n",
       " 'leg',\n",
       " 'letter',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'line',\n",
       " 'little',\n",
       " 'local',\n",
       " 'long',\n",
       " 'love',\n",
       " 'low',\n",
       " 'man',\n",
       " 'meeting',\n",
       " 'member',\n",
       " 'mind',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'mother',\n",
       " 'movie',\n",
       " 'murder',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'nearly',\n",
       " 'new',\n",
       " 'news',\n",
       " 'night',\n",
       " 'note',\n",
       " 'number',\n",
       " 'office',\n",
       " 'officer',\n",
       " 'old',\n",
       " 'open',\n",
       " 'order',\n",
       " 'outside',\n",
       " 'paper',\n",
       " 'parent',\n",
       " 'party',\n",
       " 'past',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'point',\n",
       " 'police',\n",
       " 'power',\n",
       " 'prison',\n",
       " 'question',\n",
       " 'quickly',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'reason',\n",
       " 'relationship',\n",
       " 'rest',\n",
       " 'return',\n",
       " 'right',\n",
       " 'room',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'simply',\n",
       " 'sister',\n",
       " 'situation',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'soldier',\n",
       " 'son',\n",
       " 'soon',\n",
       " 'station',\n",
       " 'story',\n",
       " 'street',\n",
       " 'suddenly',\n",
       " 'table',\n",
       " 'thing',\n",
       " 'time',\n",
       " 'town',\n",
       " 'train',\n",
       " 'tree',\n",
       " 'true',\n",
       " 'unable',\n",
       " 'voice',\n",
       " 'wall',\n",
       " 'war',\n",
       " 'water',\n",
       " 'way',\n",
       " 'well',\n",
       " 'wife',\n",
       " 'window',\n",
       " 'woman',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'young']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vokabular\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Means-Clustering\n",
    "\n",
    "Nachdem wir nun einen validen Input generiert haben, können wir mit dem mit der Modellierung unseres Clustering Algorithmus fortfahren. Wir nutzen hier für den so genannten `k-Means`-Algorithmus, der aus einer Menge von ähnlichen Objekten eine zuvor definierte Anzahl an Clustern bildet. Hierfür nutzen wir ebenfalls `sklearn`. \n",
    "\n",
    "Ein gängier Ansatz bei der Evaluierung von Clustering-Algorithmen ist es, den Algorithmus in einer Schleife bis zu einem bestimmten Schwellwert an Clustern auszuführen. Man nutzt dabei eine Metrik, um die Performanz des Algorithmus zu messen. sklearns `inertia` bietet eine Schnittstelle zur Berechnung der `within-cluster sum-of-squares (WSS)` zur Berechnung der Summe der quadrierten Abweichungen von den Cluster-Schwerpunkten. Valide Werte für die Anzahl an Clustern bei unseren Daten sind: 1, ..., 237. 237 Cluster sind dennoch nicht sinnvoll, da wir so jeden Dateneintrag einem eigenen Cluster zuordnen würden. Wir definieren unsere maximale Anzahl an Clustern, welche für uns die verschiedenen Genres der Filmhandlungen darstellen sollen, als 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wss = []\n",
    "limit = 11\n",
    "for k in range(1, limit):\n",
    "    model = KMeans(n_clusters=k, max_iter=100)\n",
    "    model.fit(X)\n",
    "    wss.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Aussage zum Wählen einer bestimmten Anzahl an Clustern treffen zu können plotten wir mithilfe von Matplotlib alle WSS. Wir wählen dabei eine Zahl, welche einen \"Knick\" / niedrigere Steigung aufweist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, limit), wss)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('WSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisevaluierung\n",
    "\n",
    "Wir evaluieren unseren Algorithmus auf unseren Daten fortgehend mit einer Anzahl von 7 Clustern/Genren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 7\n",
    "model = KMeans(n_clusters=k, init='k-means++', max_iter=100)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Algorithmus terminiert nach 12 Iterationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WSS aktueller Cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.7776604048724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir fügen alle Cluster-Zuordnung als neue Spalte in unserem DataFrame an, damit man eine direkte Zuordnung zwischen Filmtitel und Cluster hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cluster'] = model.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bow</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>banker wife lover golf pro state death penalty...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>movie gang man clown mask bank mob large porti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>guest wedding reception daughter connie head f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>godfather ii parallel storyline chief event mo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>restaurant young couple pro con bank versus li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  The Shawshank Redemption   \n",
       "1           The Dark Knight   \n",
       "2             The Godfather   \n",
       "3    The Godfather: Part II   \n",
       "4              Pulp Fiction   \n",
       "\n",
       "                                                 bow  cluster  \n",
       "0  banker wife lover golf pro state death penalty...        0  \n",
       "1  movie gang man clown mask bank mob large porti...        0  \n",
       "2  guest wedding reception daughter connie head f...        4  \n",
       "3  godfather ii parallel storyline chief event mo...        4  \n",
       "4  restaurant young couple pro con bank versus li...        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustermerkmale\n",
    "\n",
    "\n",
    "Man kann nun die Eigenschaften eines Clusters untersuchen, in dem man sich die relevantesten Token der einzelnen Cluster anschaut. Dafür iteriert man über jedes einzelne Cluster und gibt eine bestimmte Anzahl an relevantesten Tokens, welche am nächsten zum Mittelpunkt des Clusters sind, aus. Wir können ebenfalls für jedes Cluster ein paar Filme ausgeben, um das Cluster genauer beschreiben zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "police, man, car, room, prison, officer, money, time, guard, job, away, film, building, house, friend\n",
      "\n",
      "Cluster 1:\n",
      "car, apartment, man, money, gun, home, time, room, away, police, wife, street, door, friend, life\n",
      "\n",
      "Cluster 2:\n",
      "life, letter, story, film, friend, husband, time, wife, love, new, child, man, boy, school, book\n",
      "\n",
      "Cluster 3:\n",
      "room, door, voice, away, man, time, new, group, inside, power, suddenly, wall, head, like, large\n",
      "\n",
      "Cluster 4:\n",
      "family, father, mother, son, house, daughter, old, child, home, girl, police, wife, young, sister, time\n",
      "\n",
      "Cluster 5:\n",
      "man, town, brother, money, girl, son, home, father, house, woman, wife, hand, train, away, local\n",
      "\n",
      "Cluster 6:\n",
      "soldier, man, officer, war, father, attack, battle, fire, gun, time, group, train, death, escape, woman\n"
     ]
    }
   ],
   "source": [
    "true_k = np.unique(data['cluster']).shape[0]\n",
    "# Indizes von Tokens pro Cluster nach Relevanz sortieren\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "# 10 wichtigsten Tokens von jeweiligem Cluster ausgeben\n",
    "for i in range(true_k):\n",
    "    print(\"\\nCluster {}:\\n{}\".format(i, ', '.join(feature_names[ind] for ind in order_centroids[i, :15])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterzuordnungen\n",
    "\n",
    "Wir können dann versuchen jedes Cluster durch ein Genre zu beschreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0: 24 Filme\n",
      "The Shawshank Redemption, The Dark Knight, The Usual Suspects, The Departed, The Intouchables, The Dark Knight Rises, Sunset Blvd., Reservoir Dogs, A Clockwork Orange, North by Northwest\n",
      "\n",
      "Cluster 1: 33 Filme\n",
      "Pulp Fiction, Fight Club, Inception, Goodfellas, Back to the Future, Léon: The Professional, Joker, Oldboy, The Lives of Others, Andhadhun\n",
      "\n",
      "Cluster 2: 44 Filme\n",
      "12 Angry Men, Hamilton, Forrest Gump, Anand, Cinema Paradiso, Casablanca, Avengers: Endgame, Once Upon a Time in America, Memento, Good Will Hunting\n",
      "\n",
      "Cluster 3: 44 Filme\n",
      "The Lord of the Rings: The Return of the King, The Lord of the Rings: The Fellowship of the Ring, Terminator 2: Judgment Day, The Lion King, Whiplash, Seven Samurai, Avengers: Infinity War, Spider-Man: Into the Spider-Verse, The Shining, WALL·E\n",
      "\n",
      "Cluster 4: 32 Filme\n",
      "The Godfather, The Godfather: Part II, Psycho, Grave of the Fireflies, Gladiator, The Pianist, 3 Idiots, Coco, Dangal, The Hunt\n",
      "\n",
      "Cluster 5: 36 Filme\n",
      "Schindler's List, Once Upon a Time in the West, American History X, The Prestige, It's a Wonderful Life, Django Unchained, Princess Mononoke, City Lights, Your Name., Lawrence of Arabia\n",
      "\n",
      "Cluster 6: 24 Filme\n",
      "The Good, the Bad and the Ugly, Raiders of the Lost Ark, Paths of Glory, 1917, The Great Dictator, Inglourious Basterds, Braveheart, Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb, Apocalypse Now, Saving Private Ryan\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(set(model.labels_))):\n",
    "    indices = np.where(data['cluster'] == i)[0].tolist()\n",
    "    print('\\nCluster {}: {} Filme\\n{}'.format(i, len(indices), ', '.join([data['title'][j] for j in indices[:10]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cluster 0: Abenteuer\n",
    "* Cluster 1: Action, Krimi\n",
    "* Cluster 2: Drama, Krimi\n",
    "* Cluster 3: Emotionales Drama\n",
    "* Cluster 4: Action, Abenteuer, Scifi, Krieg\n",
    "*  Cluster 5: Misteriös, Drama, Krieg\n",
    "* Cluster 6: Drama, History, Gewalt\n",
    "\n",
    "Was ebenfalls für die Clusteraufteilung spricht ist der Fakt, dass Sequels mit ähnlicher Story dem gleichen Cluster zugeordnet wurden, siehe beispielsweise: Der Herr der Ringe, der Pate. Trotzdem gibt es ein paar Filme die sich inhaltlich von anderen innerhalb des gleichen Clusters unterschieden, wie beispielsweise Inception und Toy Story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ähnlichkeitsanalyse der Filme eines Clusters\n",
    "\n",
    "Nachdem wir nun Filme einem bestimmten Schorre zugeordnet haben, können wir die Ähnlichkeiten verschiedene Filme berechnen. Am sinnvollsten ist es Filme des gleichen Clusters zu vergleichen, da diese sich inhaltlich am ähnlichsten sind.\n",
    "\n",
    "spaCy bietet hierfür eine Methode namens `similarity()`, die die Kosinus Ähnlichkeit zwischen zwei Vektoren (z.B. Token oder Dokumenten) berechnet. spaCy setzt hierfür voraus, dass man ein Sprachmodell verwendet, welches über Wort Vektoren verfügt. Wir importieren deswegen zuerst ein umfangreicheres Sprachmodell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweitertes Sprachmodel laden (enthält Vekoren)\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Algorithmus berechnet somit für jeden Film in jedem Cluster mit jedem weiteren Film des Clusters dessen Kosinus Ähnlichkeit und speichert diese gerundet in einer Confusion Matrix. Man erhält folgende Tabelle, wobei jede Reihe einen Film darstellt und jede Spalte dessen Änlichkeit zu einem weiteren Film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in range(k):\n",
    "    indices_cluster = data.index[data['cluster'] == i].tolist()\n",
    "    for j in range(len(indices_cluster)):\n",
    "        row = {'title': data['title'][indices_cluster[j]]}\n",
    "        for y in range(len(indices_cluster)):\n",
    "            row[data['title'][indices_cluster[y]]] = round(nlp(data['bow'][indices_cluster[j]]).similarity(nlp(data['bow'][indices_cluster[y]])), 3)\n",
    "        values.append(row)\n",
    "similarity = pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max-Normalisierung\n",
    "\n",
    "Wie man zuvor erkennen konnte, sind die Ähnlichkeiten aller Filme eines Clusters relativ hoch. Dies liegt an der doch größeren Anzahl an selben Wörtern in jeder Zusammenfassung. Es bietet sich daher an alle Ergebnisse zu normalisieren, um ein breiteres Spektrum an Ähnlichkeiten zu erhalten. Die sogenannte Min-Max-Normalisierung bietet sich dafür an. Es wird der minimale- und maximale Wert der Confusion Matrix benötigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima = min(similarity.min(axis = 1).values)\n",
    "minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima = max(similarity.max(axis = 1).values)\n",
    "maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird vorrübergehend die Spalte der Titel entfernt, damit alle Werte Zahlen entsprechen und normalisiert werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = similarity['title']\n",
    "similarity = similarity.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand der folgenden Formel können unsere Daten normalisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (similarity - min(similarity.min(axis = 1).values))/(max(similarity.max(axis = 1).values) - min(similarity.min(axis = 1).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir konkatinieren wiederrum unsere Titel-Spalte mit den nun normalisieren Ähnlichkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = pd.concat([titles, similarity], axis=1)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Werte wurden somit auf einen Wertebereich zwischen 0 und 1 skaliert, wobei 0 einer Ähnlichkeit von 0.788 und 1 einer Ähnlichkeit von 1 entspricht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel: Filmempfehlung\n",
    "\n",
    "Ein letztes Beispiel soll nun unseren anfänglich definierten Anwendungsfall darstellen. Wir gehen davon aus, dass ein Nutzer den Film Inception angesehen hat, begeistert war und nun einen möglichst ähnlichen Titel schauen möchte. \n",
    "\n",
    "Wir identifizieren hierfür den Film Inception in unserer Datenstruktur (in einer realen Anwendung beispielsweise eine Datenbank). Wir transponieren nun unseren Datensatz bestehend aus einem Film und dessen Ähnlichkeiten zu weiteren Filmen aus dem gleichen Cluster, um einen Spaltenvektor zu erlangen. Schlussendlich sortieren wir unsere Liste der Ähnlichkeiten in absteigender Reihenfolge (\"Order By\"-Statement Datenbank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achsen swappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = similarity.iloc[[0]]\n",
    "inception = inception.T\n",
    "inception = inception.drop(inception.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sind nun in der Lage Vorschläge an inhaltlich ähnlichen Titel auszusprechen. Wir können hierfür eine Reihe von Filmen (siehe Netflix-Beispiel Übersicht) visualisieren oder einen einzelnen Film ausgeben. Man muss beachten, dass man hierbei den gleichen Titel nicht vorschlägt. In einem realen Anwendungsfall könnte man ebenfalls alle Titel, welche der Nutzer bereits gesehen hat, exkludieren. Beispielsweise könnte man dem Nutzer als nächstes den Film: Die Truman Show empfehlen. Dieser passt inhaltlich zu Inception, da in beiden Filmen teilweise um eine Simulation dreht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Mithilfe einer durch einen Crawler erstellten Datenbasis, geeigneten Vorverarbeitung der Daten und k-Means Clustering Algorithmus konnten wir unsere Daten bestehend aus Film Zusammenfassungen inhaltlich Clustern. Mithilfe der Kosinus Ähnlichkeit konnten wir alle Filme in einem Cluster vergleichen um letztendlich einen Teil eines realen Anwendungsfalls von Natural Language Processing und Maschinen Learning in Streaming-Anwendungen abzubilden.\n",
    "\n",
    "* [Zurück zur Übersicht](./0_nlp_intro_schlaak_weise.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
