{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation der Daten\n",
    "\n",
    "In diesem Notebook möchten wir eine Cluster Analyse unserer zuvor vor verarbeiteten Daten durchführen, um inhaltlich ähnliche Filme zu einem Genre zu ordnen zu können. basierend darauf soll eine Ähnlichkeitsanalyse innerhalb jedes Clusters durchgeführt werden, um Vorschläge für ähnliche Titel aussprechen zu können.\n",
    "\n",
    "## Module importieren\n",
    "\n",
    "Zur Verarbeitung der Datenbasis werden folgende Module benötigt und müssen zuerst importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../data/movies.json'\n",
    "# JSON Daten in Dataframe lesen\n",
    "data = pd.read_json(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenbereinigung\n",
    "\n",
    "Entfernen der Dateneinträge ohne Zusammenfassung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    }
   ],
   "source": [
    "disclaimer = 'It looks like we don\\'t have a Synopsis for this title yet.'\n",
    "for index, movie in data.iterrows():\n",
    "    if disclaimer in movie['synopsis']:\n",
    "        data = data.drop(index)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorverarbeitung der Daten\n",
    "\n",
    "Lemmatisierung der Token, sowie entfernen von Stoppwörtern, Eigennamen und Verben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for index, movie in data.iterrows():\n",
    "    # Vorverarbeiten der Zusammenfassungen\n",
    "    processed_data.append({'title': movie['title'], 'bow': ' '.join([str(token.lemma_).lower() for token in nlp(movie['synopsis']) if not token.ent_type_ and not token.is_stop and not token.is_punct and token.pos_ != 'VERB'])})\n",
    "data = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das DataFrame sieht nun folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>banker wife lover golf pro state death penalty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>movie gang man clown mask bank mob large porti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>guest wedding reception daughter connie head f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>godfather ii parallel storyline chief event mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>restaurant young couple pro con bank versus li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title                                                bow\n",
       "0  The Shawshank Redemption  banker wife lover golf pro state death penalty...\n",
       "1           The Dark Knight  movie gang man clown mask bank mob large porti...\n",
       "2             The Godfather  guest wedding reception daughter connie head f...\n",
       "3    The Godfather: Part II  godfather ii parallel storyline chief event mo...\n",
       "4              Pulp Fiction  restaurant young couple pro con bank versus li..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nur erste fünf Einträge anzeigen\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-Matrix erstellen\n",
    "\n",
    "\n",
    "Damit wir unsere vorverarbeitenden Bag of Words als Eingabe für unsere Cluster Algorithmus verwenden können erstellen wir eine so genannte Feature Matrix. Dabei generieren wir eine Matrix der Häufigkeit aller Token unsere Dateneinträge mithilfe des von `sklearn`s `CountVectorizer` gefolgt von einer Normalisierung mittels `TfidfTransformer` der Daten. Wir nutzen hierbei die Inverse Dokument Frequency (inverse Dokumentenhäufigkeit). Die inverse Dokumenthäufigkeit misst die Spezifität eines Terms für die Gesamtmenge der betrachteten Dokumente. Ein übereinstimmendes Vorkommen von seltenen Begriffen ist für die Relevanz aussagekräftiger als eine Übereinstimmung bei sehr häufigen Wörtern [[Quelle]](https://de.wikipedia.org/wiki/Tf-idf-Ma%C3%9F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix von Token mit Frequenz plus Normalisieren mittels \"Inverse-document-frequency\" (IDF)\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.2, ngram_range=(1,3))\n",
    "# Lernen des Vokabulars und IDF\n",
    "X = vectorizer.fit_transform(data['bow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere Feature Matrix besteht somit aus 237 Einträgen, die jeweils über 196 Wörter/Token verfügen. Jeder Dateneintrag besitzt selbstverständlich nicht jedes Wort und hat deshalb bei mehreren Token eine Frequenz von 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 196)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten folgende Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0353196 , 0.02406543, 0.        , ..., 0.02499595, 0.07219628,\n",
       "        0.01581857],\n",
       "       [0.04885937, 0.02219394, 0.04252334, ..., 0.        , 0.02219394,\n",
       "        0.02917682],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.12084285],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.04800141, ..., 0.        , 0.        ,\n",
       "        0.06587104],\n",
       "       [0.        , 0.        , 0.        , ..., 0.07059206, 0.        ,\n",
       "        0.13402154],\n",
       "       [0.0483163 , 0.06584177, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten somit 196 Wörter, welche das für dieses Projekt benötigte Vokabular darstellen. Bei einer Optimierung dieses Projekts könnte man beispielsweise dieses Vokabular  (erweitert mit Stoppwörtern, Satzzeichen) anstatt eines der von spaCy zur Verügung gestellten Sprachmodelle nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'action',\n",
       " 'actually',\n",
       " 'alive',\n",
       " 'angry',\n",
       " 'apartment',\n",
       " 'apparently',\n",
       " 'area',\n",
       " 'arm',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'away',\n",
       " 'bad',\n",
       " 'bar',\n",
       " 'battle',\n",
       " 'bed',\n",
       " 'big',\n",
       " 'black',\n",
       " 'blood',\n",
       " 'body',\n",
       " 'book',\n",
       " 'boy',\n",
       " 'brother',\n",
       " 'building',\n",
       " 'business',\n",
       " 'car',\n",
       " 'case',\n",
       " 'chance',\n",
       " 'charge',\n",
       " 'child',\n",
       " 'city',\n",
       " 'close',\n",
       " 'company',\n",
       " 'completely',\n",
       " 'control',\n",
       " 'conversation',\n",
       " 'couple',\n",
       " 'crime',\n",
       " 'dark',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'despite',\n",
       " 'different',\n",
       " 'doctor',\n",
       " 'door',\n",
       " 'earlier',\n",
       " 'end',\n",
       " 'entire',\n",
       " 'escape',\n",
       " 'event',\n",
       " 'eventually',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'family',\n",
       " 'far',\n",
       " 'father',\n",
       " 'fight',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'fire',\n",
       " 'floor',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'force',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'game',\n",
       " 'girl',\n",
       " 'good',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'guard',\n",
       " 'gun',\n",
       " 'hand',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'head',\n",
       " 'help',\n",
       " 'high',\n",
       " 'home',\n",
       " 'hospital',\n",
       " 'house',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'immediately',\n",
       " 'information',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'job',\n",
       " 'large',\n",
       " 'late',\n",
       " 'later',\n",
       " 'leg',\n",
       " 'letter',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'line',\n",
       " 'little',\n",
       " 'local',\n",
       " 'long',\n",
       " 'love',\n",
       " 'low',\n",
       " 'man',\n",
       " 'meeting',\n",
       " 'member',\n",
       " 'mind',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'mother',\n",
       " 'movie',\n",
       " 'murder',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'nearly',\n",
       " 'new',\n",
       " 'news',\n",
       " 'night',\n",
       " 'note',\n",
       " 'number',\n",
       " 'office',\n",
       " 'officer',\n",
       " 'old',\n",
       " 'open',\n",
       " 'order',\n",
       " 'outside',\n",
       " 'paper',\n",
       " 'parent',\n",
       " 'party',\n",
       " 'past',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'point',\n",
       " 'police',\n",
       " 'power',\n",
       " 'prison',\n",
       " 'question',\n",
       " 'quickly',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'reason',\n",
       " 'relationship',\n",
       " 'rest',\n",
       " 'return',\n",
       " 'right',\n",
       " 'room',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'simply',\n",
       " 'sister',\n",
       " 'situation',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'soldier',\n",
       " 'son',\n",
       " 'soon',\n",
       " 'station',\n",
       " 'story',\n",
       " 'street',\n",
       " 'suddenly',\n",
       " 'table',\n",
       " 'thing',\n",
       " 'time',\n",
       " 'town',\n",
       " 'train',\n",
       " 'tree',\n",
       " 'true',\n",
       " 'unable',\n",
       " 'voice',\n",
       " 'wall',\n",
       " 'war',\n",
       " 'water',\n",
       " 'way',\n",
       " 'well',\n",
       " 'wife',\n",
       " 'window',\n",
       " 'woman',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'young']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vokabular\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Means-Clustering\n",
    "\n",
    "Nachdem wir nun einen validen Input generiert haben, können wir mit dem mit der Modellierung unseres Clustering Algorithmus fortfahren. Wir nutzen hier für den so genannten `k-Means`-Algorithmus, der aus einer Menge von ähnlichen Objekten eine zuvor definierte Anzahl an Clustern bildet. Hierfür nutzen wir ebenfalls `sklearn`. \n",
    "\n",
    "Ein gängier Ansatz bei der Evaluierung von Clustering-Algorithmen ist es, den Algorithmus in einer Schleife bis zu einem bestimmten Schwellwert an Clustern auszuführen. Man nutzt dabei eine Metrik, um die Performanz des Algorithmus zu messen. sklearns `inertia` bietet eine Schnittstelle zur Berechnung der `within-cluster sum-of-squares (WSS)` zur Berechnung der Summe der quadrierten Abweichungen von den Cluster-Schwerpunkten. Valide Werte für die Anzahl an Clustern bei unseren Daten sind: 1, ..., 237. 237 Cluster sind dennoch nicht sinnvoll, da wir so jeden Dateneintrag einem eigenen Cluster zuordnen würden. Wir definieren unsere maximale Anzahl an Clustern, welche für uns die verschiedenen Genres der Filmhandlungen darstellen sollen, als 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wss = []\n",
    "limit = 11\n",
    "for k in range(1, limit):\n",
    "    model = KMeans(n_clusters=k, max_iter=100)\n",
    "    model.fit(X)\n",
    "    wss.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Aussage zum Wählen einer bestimmten Anzahl an Clustern treffen zu können plotten wir mithilfe von Matplotlib alle WSS. Wir wählen dabei eine Zahl, welche einen \"Knick\" / niedrigere Steigung aufweist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, limit), wss)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('WSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisevaluierung\n",
    "\n",
    "Wir evaluieren unseren Algorithmus auf unseren Daten fortgehend mit einer Anzahl von 7 Clustern/Genren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 7\n",
    "model = KMeans(n_clusters=k, init='k-means++', max_iter=100)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Algorithmus terminiert nach 8 Iterationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WSS aktueller Cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.88774168891274"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir fügen alle Cluster-Zuordnung als neue Spalte in unserem DataFrame an, damit man eine direkte Zuordnung zwischen Filmtitel und Cluster hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cluster'] = model.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bow</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>banker wife lover golf pro state death penalty...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>movie gang man clown mask bank mob large porti...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>guest wedding reception daughter connie head f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>godfather ii parallel storyline chief event mo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>restaurant young couple pro con bank versus li...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  The Shawshank Redemption   \n",
       "1           The Dark Knight   \n",
       "2             The Godfather   \n",
       "3    The Godfather: Part II   \n",
       "4              Pulp Fiction   \n",
       "\n",
       "                                                 bow  cluster  \n",
       "0  banker wife lover golf pro state death penalty...        4  \n",
       "1  movie gang man clown mask bank mob large porti...        5  \n",
       "2  guest wedding reception daughter connie head f...        3  \n",
       "3  godfather ii parallel storyline chief event mo...        3  \n",
       "4  restaurant young couple pro con bank versus li...        2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustermerkmale\n",
    "\n",
    "\n",
    "Man kann nun die Eigenschaften eines Clusters untersuchen, in dem man sich die relevantesten Token der einzelnen Cluster anschaut. Dafür iteriert man über jedes einzelne Cluster und gibt eine bestimmte Anzahl an relevantesten Tokens, welche am nächsten zum Mittelpunkt des Clusters sind, aus. Wir können ebenfalls für jedes Cluster ein paar Filme ausgeben, um das Cluster genauer beschreiben zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "life, film, wife, husband, time, friend, relationship, story, love, letter, book, child, son, mother, young\n",
      "\n",
      "Cluster 1:\n",
      "father, school, boy, parent, mother, home, letter, friend, child, new, family, time, daughter, life, train\n",
      "\n",
      "Cluster 2:\n",
      "apartment, girl, fight, door, room, home, man, car, house, away, gun, head, woman, face, time\n",
      "\n",
      "Cluster 3:\n",
      "family, house, father, police, business, man, son, car, dead, war, home, local, member, daughter, gun\n",
      "\n",
      "Cluster 4:\n",
      "man, guard, town, woman, soldier, time, away, room, wife, black, life, gun, prison, people, brother\n",
      "\n",
      "Cluster 5:\n",
      "car, police, man, money, room, house, time, home, phone, away, mother, job, wife, officer, father\n",
      "\n",
      "Cluster 6:\n",
      "soldier, battle, war, son, man, attack, officer, fire, power, father, city, force, time, group, hand\n"
     ]
    }
   ],
   "source": [
    "true_k = np.unique(data['cluster']).shape[0]\n",
    "# Indizes von Tokens pro Cluster nach Relevanz sortieren\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "# 10 wichtigsten Tokens von jeweiligem Cluster ausgeben\n",
    "for i in range(true_k):\n",
    "    print(\"\\nCluster {}:\\n{}\".format(i, ', '.join(feature_names[ind] for ind in order_centroids[i, :15])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterzuordnungen\n",
    "\n",
    "Wir können dann versuchen jedes Cluster durch ein Genre zu beschreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0: 32 Filme\n",
      "Anand, Casablanca, The Intouchables, Avengers: Endgame, The Hunt, Good Will Hunting, American Beauty, Eternal Sunshine of the Spotless Mind, Witness for the Prosecution, Life Is Beautiful\n",
      "\n",
      "Cluster 1: 34 Filme\n",
      "12 Angry Men, Forrest Gump, Grave of the Fireflies, Cinema Paradiso, Whiplash, 3 Idiots, Dangal, Once Upon a Time in America, Amélie, Children of Heaven\n",
      "\n",
      "Cluster 2: 29 Filme\n",
      "Pulp Fiction, Fight Club, Léon: The Professional, Joker, The Shining, The Lives of Others, Rear Window, Snatch, Toy Story, Toy Story 3\n",
      "\n",
      "Cluster 3: 10 Filme\n",
      "The Godfather, The Godfather: Part II, Goodfellas, The Pianist, Coco, Parasite, Drishyam, Hotel Rwanda, Gran Torino, Gangs of Wasseypur\n",
      "\n",
      "Cluster 4: 44 Filme\n",
      "The Shawshank Redemption, Schindler's List, The Good, the Bad and the Ugly, Once Upon a Time in the West, American History X, The Prestige, Django Unchained, Memento, Princess Mononoke, Oldboy\n",
      "\n",
      "Cluster 5: 45 Filme\n",
      "The Dark Knight, Inception, Psycho, Back to the Future, Terminator 2: Judgment Day, The Usual Suspects, The Departed, It's a Wonderful Life, The Dark Knight Rises, Andhadhun\n",
      "\n",
      "Cluster 6: 43 Filme\n",
      "The Lord of the Rings: The Return of the King, The Lord of the Rings: The Fellowship of the Ring, Hamilton, The Lion King, Gladiator, Seven Samurai, Avengers: Infinity War, Spider-Man: Into the Spider-Verse, Raiders of the Lost Ark, WALL·E\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(set(model.labels_))):\n",
    "    indices = np.where(data['cluster'] == i)[0].tolist()\n",
    "    print('\\nCluster {}: {} Filme\\n{}'.format(i, len(indices), ', '.join([data['title'][j] for j in indices[:10]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cluster 0: Drama, Romance\n",
    "* Cluster 1: Drama, Emotional\n",
    "* Cluster 2: Drama, Misterös, Krimi\n",
    "* Cluster 3: Drama, Krimi, Mafia\n",
    "* Cluster 4: Drama, History, Gewalt\n",
    "* Cluster 5: Action, Krimi\n",
    "* Cluster 6: Action, Abenteuer, Scifi, Krieg\n",
    "\n",
    "Was ebenfalls für die Clusteraufteilung spricht ist der Fakt, dass Sequels mit ähnlicher Story dem gleichen Cluster zugeordnet wurden, siehe beispielsweise: Der Herr der Ringe, der Pate. Trotzdem gibt es ein paar Filme die sich inhaltlich von anderen innerhalb des gleichen Clusters unterschieden, wie beispielsweise Pulp Fiction und Toy Story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ähnlichkeitsanalyse der Filme eines Clusters\n",
    "\n",
    "Nachdem wir nun Filme einem bestimmten Schorre zugeordnet haben, können wir die Ähnlichkeiten verschiedene Filme berechnen. Am sinnvollsten ist es Filme des gleichen Clusters zu vergleichen, da diese sich inhaltlich am ähnlichsten sind.\n",
    "\n",
    "spaCy bietet hierfür eine Methode namens `similarity()`, die die Kosinus Ähnlichkeit zwischen zwei Vektoren (z.B. Token oder Dokumenten) berechnet. spaCy setzt hierfür voraus, dass man ein Sprachmodell verwendet, welches über Wort Vektoren verfügt. Wir importieren deswegen zuerst ein umfangreicheres Sprachmodell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweitertes Sprachmodel laden (enthält Vekoren)\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Algorithmus berechnet somit für jeden Film in jedem Cluster mit jedem weiteren Film des Clusters dessen Kosinus Ähnlichkeit und speichert diese gerundet in einer Confusion Matrix. Man erhält folgende Tabelle, wobei jede Reihe einen Film darstellt und jede Spalte dessen Änlichkeit zu einem weiteren Film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in range(k):\n",
    "    indices_cluster = data.index[data['cluster'] == i].tolist()\n",
    "    for j in range(len(indices_cluster)):\n",
    "        row = {'title': data['title'][indices_cluster[j]]}\n",
    "        for y in range(len(indices_cluster)):\n",
    "            row[data['title'][indices_cluster[y]]] = round(nlp(data['bow'][indices_cluster[j]]).similarity(nlp(data['bow'][indices_cluster[y]])), 3)\n",
    "        values.append(row)\n",
    "similarity = pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Anand</th>\n",
       "      <th>Casablanca</th>\n",
       "      <th>The Intouchables</th>\n",
       "      <th>Avengers: Endgame</th>\n",
       "      <th>The Hunt</th>\n",
       "      <th>Good Will Hunting</th>\n",
       "      <th>American Beauty</th>\n",
       "      <th>Eternal Sunshine of the Spotless Mind</th>\n",
       "      <th>Witness for the Prosecution</th>\n",
       "      <th>...</th>\n",
       "      <th>The General</th>\n",
       "      <th>Gone with the Wind</th>\n",
       "      <th>Barry Lyndon</th>\n",
       "      <th>How to Train Your Dragon</th>\n",
       "      <th>Harry Potter and the Deathly Hallows: Part 2</th>\n",
       "      <th>Hacksaw Ridge</th>\n",
       "      <th>Downfall</th>\n",
       "      <th>Howl's Moving Castle</th>\n",
       "      <th>Judgment at Nuremberg</th>\n",
       "      <th>Metropolis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anand</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.859</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.902</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.921</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.883</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.864</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hunt</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.879</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Hacksaw Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Downfall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Howl's Moving Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.899</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Judgment at Nuremberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.780</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Metropolis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title  Anand  Casablanca  The Intouchables  \\\n",
       "0                    Anand  1.000       0.882             0.887   \n",
       "1               Casablanca  0.882       1.000             0.921   \n",
       "2         The Intouchables  0.887       0.921             1.000   \n",
       "3        Avengers: Endgame  0.887       0.931             0.895   \n",
       "4                 The Hunt  0.879       0.900             0.919   \n",
       "..                     ...    ...         ...               ...   \n",
       "232          Hacksaw Ridge    NaN         NaN               NaN   \n",
       "233               Downfall    NaN         NaN               NaN   \n",
       "234   Howl's Moving Castle    NaN         NaN               NaN   \n",
       "235  Judgment at Nuremberg    NaN         NaN               NaN   \n",
       "236             Metropolis    NaN         NaN               NaN   \n",
       "\n",
       "     Avengers: Endgame  The Hunt  Good Will Hunting  American Beauty  \\\n",
       "0                0.887     0.879              0.935            0.916   \n",
       "1                0.931     0.900              0.944            0.938   \n",
       "2                0.895     0.919              0.928            0.935   \n",
       "3                1.000     0.881              0.942            0.924   \n",
       "4                0.881     1.000              0.934            0.928   \n",
       "..                 ...       ...                ...              ...   \n",
       "232                NaN       NaN                NaN              NaN   \n",
       "233                NaN       NaN                NaN              NaN   \n",
       "234                NaN       NaN                NaN              NaN   \n",
       "235                NaN       NaN                NaN              NaN   \n",
       "236                NaN       NaN                NaN              NaN   \n",
       "\n",
       "     Eternal Sunshine of the Spotless Mind  Witness for the Prosecution  ...  \\\n",
       "0                                    0.913                        0.859  ...   \n",
       "1                                    0.888                        0.902  ...   \n",
       "2                                    0.877                        0.883  ...   \n",
       "3                                    0.907                        0.864  ...   \n",
       "4                                    0.880                        0.879  ...   \n",
       "..                                     ...                          ...  ...   \n",
       "232                                    NaN                          NaN  ...   \n",
       "233                                    NaN                          NaN  ...   \n",
       "234                                    NaN                          NaN  ...   \n",
       "235                                    NaN                          NaN  ...   \n",
       "236                                    NaN                          NaN  ...   \n",
       "\n",
       "     The General  Gone with the Wind  Barry Lyndon  How to Train Your Dragon  \\\n",
       "0            NaN                 NaN           NaN                       NaN   \n",
       "1            NaN                 NaN           NaN                       NaN   \n",
       "2            NaN                 NaN           NaN                       NaN   \n",
       "3            NaN                 NaN           NaN                       NaN   \n",
       "4            NaN                 NaN           NaN                       NaN   \n",
       "..           ...                 ...           ...                       ...   \n",
       "232        0.818               0.932         0.924                     0.828   \n",
       "233        0.861               0.960         0.943                     0.871   \n",
       "234        0.893               0.939         0.903                     0.931   \n",
       "235        0.717               0.896         0.893                     0.760   \n",
       "236        0.837               0.960         0.947                     0.882   \n",
       "\n",
       "     Harry Potter and the Deathly Hallows: Part 2  Hacksaw Ridge  Downfall  \\\n",
       "0                                             NaN            NaN       NaN   \n",
       "1                                             NaN            NaN       NaN   \n",
       "2                                             NaN            NaN       NaN   \n",
       "3                                             NaN            NaN       NaN   \n",
       "4                                             NaN            NaN       NaN   \n",
       "..                                            ...            ...       ...   \n",
       "232                                         0.869          1.000     0.938   \n",
       "233                                         0.881          0.938     1.000   \n",
       "234                                         0.929          0.843     0.899   \n",
       "235                                         0.789          0.890     0.893   \n",
       "236                                         0.885          0.898     0.942   \n",
       "\n",
       "     Howl's Moving Castle  Judgment at Nuremberg  Metropolis  \n",
       "0                     NaN                    NaN         NaN  \n",
       "1                     NaN                    NaN         NaN  \n",
       "2                     NaN                    NaN         NaN  \n",
       "3                     NaN                    NaN         NaN  \n",
       "4                     NaN                    NaN         NaN  \n",
       "..                    ...                    ...         ...  \n",
       "232                 0.843                  0.890       0.898  \n",
       "233                 0.899                  0.893       0.942  \n",
       "234                 1.000                  0.780       0.906  \n",
       "235                 0.780                  1.000       0.892  \n",
       "236                 0.906                  0.892       1.000  \n",
       "\n",
       "[237 rows x 238 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max-Normalisierung\n",
    "\n",
    "Wie man zuvor erkennen konnte, sind die Ähnlichkeiten aller Filme eines Clusters relativ hoch. Dies liegt an der doch größeren Anzahl an selben Wörtern in jeder Zusammenfassung. Es bietet sich daher an alle Ergebnisse zu normalisieren, um ein breiteres Spektrum an Ähnlichkeiten zu erhalten. Die sogenannte Min-Max-Normalisierung bietet sich dafür an. Es wird der minimale- und maximale Wert der Confusion Matrix benötigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.683"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minima = min(similarity.min(axis = 1).values)\n",
    "minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxima = max(similarity.max(axis = 1).values)\n",
    "maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird vorrübergehend die Spalte der Titel entfernt, damit alle Werte Zahlen entsprechen und normalisiert werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = similarity['title']\n",
    "similarity = similarity.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand der folgenden Formel können unsere Daten normalisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (similarity - min(similarity.min(axis = 1).values))/(max(similarity.max(axis = 1).values) - min(similarity.min(axis = 1).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir konkatinieren wiederrum unsere Titel-Spalte mit den nun normalisieren Ähnlichkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Anand</th>\n",
       "      <th>Casablanca</th>\n",
       "      <th>The Intouchables</th>\n",
       "      <th>Avengers: Endgame</th>\n",
       "      <th>The Hunt</th>\n",
       "      <th>Good Will Hunting</th>\n",
       "      <th>American Beauty</th>\n",
       "      <th>Eternal Sunshine of the Spotless Mind</th>\n",
       "      <th>Witness for the Prosecution</th>\n",
       "      <th>...</th>\n",
       "      <th>The General</th>\n",
       "      <th>Gone with the Wind</th>\n",
       "      <th>Barry Lyndon</th>\n",
       "      <th>How to Train Your Dragon</th>\n",
       "      <th>Harry Potter and the Deathly Hallows: Part 2</th>\n",
       "      <th>Hacksaw Ridge</th>\n",
       "      <th>Downfall</th>\n",
       "      <th>Howl's Moving Castle</th>\n",
       "      <th>Judgment at Nuremberg</th>\n",
       "      <th>Metropolis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anand</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627760</td>\n",
       "      <td>0.643533</td>\n",
       "      <td>0.643533</td>\n",
       "      <td>0.618297</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.735016</td>\n",
       "      <td>0.725552</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>0.627760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750789</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>0.823344</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.646688</td>\n",
       "      <td>0.690852</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>0.643533</td>\n",
       "      <td>0.750789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.668770</td>\n",
       "      <td>0.744479</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.611987</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>0.643533</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>0.668770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624606</td>\n",
       "      <td>0.817035</td>\n",
       "      <td>0.760252</td>\n",
       "      <td>0.706625</td>\n",
       "      <td>0.570978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hunt</td>\n",
       "      <td>0.618297</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>0.744479</td>\n",
       "      <td>0.624606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791798</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.621451</td>\n",
       "      <td>0.618297</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Hacksaw Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425868</td>\n",
       "      <td>0.785489</td>\n",
       "      <td>0.760252</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.504732</td>\n",
       "      <td>0.652997</td>\n",
       "      <td>0.678233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Downfall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.873817</td>\n",
       "      <td>0.820189</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>0.624606</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681388</td>\n",
       "      <td>0.662461</td>\n",
       "      <td>0.817035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Howl's Moving Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662461</td>\n",
       "      <td>0.807571</td>\n",
       "      <td>0.694006</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>0.776025</td>\n",
       "      <td>0.504732</td>\n",
       "      <td>0.681388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305994</td>\n",
       "      <td>0.703470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Judgment at Nuremberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107256</td>\n",
       "      <td>0.671924</td>\n",
       "      <td>0.662461</td>\n",
       "      <td>0.242902</td>\n",
       "      <td>0.334385</td>\n",
       "      <td>0.652997</td>\n",
       "      <td>0.662461</td>\n",
       "      <td>0.305994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Metropolis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485804</td>\n",
       "      <td>0.873817</td>\n",
       "      <td>0.832808</td>\n",
       "      <td>0.627760</td>\n",
       "      <td>0.637224</td>\n",
       "      <td>0.678233</td>\n",
       "      <td>0.817035</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title     Anand  Casablanca  The Intouchables  \\\n",
       "0                    Anand  1.000000    0.627760          0.643533   \n",
       "1               Casablanca  0.627760    1.000000          0.750789   \n",
       "2         The Intouchables  0.643533    0.750789          1.000000   \n",
       "3        Avengers: Endgame  0.643533    0.782334          0.668770   \n",
       "4                 The Hunt  0.618297    0.684543          0.744479   \n",
       "..                     ...       ...         ...               ...   \n",
       "232          Hacksaw Ridge       NaN         NaN               NaN   \n",
       "233               Downfall       NaN         NaN               NaN   \n",
       "234   Howl's Moving Castle       NaN         NaN               NaN   \n",
       "235  Judgment at Nuremberg       NaN         NaN               NaN   \n",
       "236             Metropolis       NaN         NaN               NaN   \n",
       "\n",
       "     Avengers: Endgame  The Hunt  Good Will Hunting  American Beauty  \\\n",
       "0             0.643533  0.618297           0.794953         0.735016   \n",
       "1             0.782334  0.684543           0.823344         0.804416   \n",
       "2             0.668770  0.744479           0.772871         0.794953   \n",
       "3             1.000000  0.624606           0.817035         0.760252   \n",
       "4             0.624606  1.000000           0.791798         0.772871   \n",
       "..                 ...       ...                ...              ...   \n",
       "232                NaN       NaN                NaN              NaN   \n",
       "233                NaN       NaN                NaN              NaN   \n",
       "234                NaN       NaN                NaN              NaN   \n",
       "235                NaN       NaN                NaN              NaN   \n",
       "236                NaN       NaN                NaN              NaN   \n",
       "\n",
       "     Eternal Sunshine of the Spotless Mind  Witness for the Prosecution  ...  \\\n",
       "0                                 0.725552                     0.555205  ...   \n",
       "1                                 0.646688                     0.690852  ...   \n",
       "2                                 0.611987                     0.630915  ...   \n",
       "3                                 0.706625                     0.570978  ...   \n",
       "4                                 0.621451                     0.618297  ...   \n",
       "..                                     ...                          ...  ...   \n",
       "232                                    NaN                          NaN  ...   \n",
       "233                                    NaN                          NaN  ...   \n",
       "234                                    NaN                          NaN  ...   \n",
       "235                                    NaN                          NaN  ...   \n",
       "236                                    NaN                          NaN  ...   \n",
       "\n",
       "     The General  Gone with the Wind  Barry Lyndon  How to Train Your Dragon  \\\n",
       "0            NaN                 NaN           NaN                       NaN   \n",
       "1            NaN                 NaN           NaN                       NaN   \n",
       "2            NaN                 NaN           NaN                       NaN   \n",
       "3            NaN                 NaN           NaN                       NaN   \n",
       "4            NaN                 NaN           NaN                       NaN   \n",
       "..           ...                 ...           ...                       ...   \n",
       "232     0.425868            0.785489      0.760252                  0.457413   \n",
       "233     0.561514            0.873817      0.820189                  0.593060   \n",
       "234     0.662461            0.807571      0.694006                  0.782334   \n",
       "235     0.107256            0.671924      0.662461                  0.242902   \n",
       "236     0.485804            0.873817      0.832808                  0.627760   \n",
       "\n",
       "     Harry Potter and the Deathly Hallows: Part 2  Hacksaw Ridge  Downfall  \\\n",
       "0                                             NaN            NaN       NaN   \n",
       "1                                             NaN            NaN       NaN   \n",
       "2                                             NaN            NaN       NaN   \n",
       "3                                             NaN            NaN       NaN   \n",
       "4                                             NaN            NaN       NaN   \n",
       "..                                            ...            ...       ...   \n",
       "232                                      0.586751       1.000000  0.804416   \n",
       "233                                      0.624606       0.804416  1.000000   \n",
       "234                                      0.776025       0.504732  0.681388   \n",
       "235                                      0.334385       0.652997  0.662461   \n",
       "236                                      0.637224       0.678233  0.817035   \n",
       "\n",
       "     Howl's Moving Castle  Judgment at Nuremberg  Metropolis  \n",
       "0                     NaN                    NaN         NaN  \n",
       "1                     NaN                    NaN         NaN  \n",
       "2                     NaN                    NaN         NaN  \n",
       "3                     NaN                    NaN         NaN  \n",
       "4                     NaN                    NaN         NaN  \n",
       "..                    ...                    ...         ...  \n",
       "232              0.504732               0.652997    0.678233  \n",
       "233              0.681388               0.662461    0.817035  \n",
       "234              1.000000               0.305994    0.703470  \n",
       "235              0.305994               1.000000    0.659306  \n",
       "236              0.703470               0.659306    1.000000  \n",
       "\n",
       "[237 rows x 238 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = pd.concat([titles, similarity], axis=1)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Werte wurden somit auf einen Wertebereich zwischen 0 und 1 skaliert, wobei 0 einer Ähnlichkeit von 0.683 und 1 einer Ähnlichkeit von 1 entspricht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel: Filmempfehlung\n",
    "\n",
    "Ein letztes Beispiel soll nun unseren anfänglich definierten Anwendungsfall darstellen. Wir gehen davon aus, dass ein Nutzer den Film Inception angesehen hat, begeistert war und nun einen möglichst ähnlichen Titel schauen möchte. \n",
    "\n",
    "Wir identifizieren hierfür den Film Inception in unserer Datenstruktur (in einer realen Anwendung beispielsweise eine Datenbank). Wir transponieren nun unseren Datensatz bestehend aus einem Film und dessen Ähnlichkeiten zu weiteren Filmen aus dem gleichen Cluster, um einen Spaltenvektor zu erlangen. Schlussendlich sortieren wir unsere Liste der Ähnlichkeiten in absteigender Reihenfolge (\"Order By\"-Statement Datenbank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achsen swappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anand</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Casablanca</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Intouchables</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avengers: Endgame</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hunt</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacksaw Ridge</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downfall</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Howl's Moving Castle</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Judgment at Nuremberg</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metropolis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       150\n",
       "Anand                  NaN\n",
       "Casablanca             NaN\n",
       "The Intouchables       NaN\n",
       "Avengers: Endgame      NaN\n",
       "The Hunt               NaN\n",
       "...                    ...\n",
       "Hacksaw Ridge          NaN\n",
       "Downfall               NaN\n",
       "Howl's Moving Castle   NaN\n",
       "Judgment at Nuremberg  NaN\n",
       "Metropolis             NaN\n",
       "\n",
       "[237 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = similarity.loc[similarity['title'] == 'Inception']\n",
    "inception = inception.T\n",
    "inception = inception.drop(inception.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Truman Show</th>\n",
       "      <td>0.933754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batman Begins</th>\n",
       "      <td>0.899054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Wolf of Wall Street</th>\n",
       "      <td>0.886435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Back to the Future</th>\n",
       "      <td>0.886435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacksaw Ridge</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downfall</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Howl's Moving Castle</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Judgment at Nuremberg</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metropolis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              150\n",
       "Inception                       1\n",
       "The Truman Show          0.933754\n",
       "Batman Begins            0.899054\n",
       "The Wolf of Wall Street  0.886435\n",
       "Back to the Future       0.886435\n",
       "...                           ...\n",
       "Hacksaw Ridge                 NaN\n",
       "Downfall                      NaN\n",
       "Howl's Moving Castle          NaN\n",
       "Judgment at Nuremberg         NaN\n",
       "Metropolis                    NaN\n",
       "\n",
       "[237 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception.sort_values(by=[150], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sind nun in der Lage Vorschläge an inhaltlich ähnlichen Titel auszusprechen. Wir können hierfür eine Reihe von Filmen (siehe Netflix-Beispiel Übersicht) visualisieren oder einen einzelnen Film ausgeben. Man muss beachten, dass man hierbei den gleichen Titel nicht vorschlägt. In einem realen Anwendungsfall könnte man ebenfalls alle Titel, welche der Nutzer bereits gesehen hat, exkludieren. Beispielsweise könnte man dem Nutzer als nächstes den Film: Die Truman Show empfehlen. Dieser passt inhaltlich zu Inception, da es sich in beiden Filmen teilweise um eine Simulation dreht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Mithilfe einer durch einen Crawler erstellten Datenbasis, geeigneten Vorverarbeitung der Daten und k-Means Clustering Algorithmus konnten wir unsere Daten bestehend aus Film Zusammenfassungen inhaltlich Clustern. Mithilfe der Kosinus Ähnlichkeit konnten wir alle Filme in einem Cluster vergleichen um letztendlich einen Teil eines realen Anwendungsfalls von Natural Language Processing und Maschinen Learning in Streaming-Anwendungen abzubilden.\n",
    "\n",
    "* [Zurück zur Übersicht](./0_nlp_intro_schlaak_weise.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
